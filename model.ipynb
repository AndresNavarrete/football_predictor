{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_PATH = \"data/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_fitting_summary(regressor, data, target):\n",
    "    predictions = regressor.predict(data)\n",
    "    errors_squared = (predictions - target) ** 2\n",
    "    \n",
    "    print('Mean Squared Error:', round(np.mean(errors_squared), 2), 'degrees.')\n",
    "\n",
    "    score = regressor.score(data, target)\n",
    "    print('R2:', round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_database():\n",
    "    df = pd.read_csv(f\"{ML_PATH}/df_history.csv\")\n",
    "    df[\"diff_h_a\"] = df.GF-df.GA\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_database(df):\n",
    "    target_name = \"diff_h_a\"\n",
    "    not_usefull_columns = [\n",
    "        target_name,\n",
    "        'home',\n",
    "        'away',\n",
    "        'GF',\n",
    "        'GA',    \n",
    "        ]\n",
    "\n",
    "    features = df.drop(columns=not_usefull_columns)\n",
    "    target = df[target_name]\n",
    "    return features, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_encoder(data, categoical_columns, numeric_columns):\n",
    "\n",
    "    float_columns_selector = selector(dtype_include=\"float\")\n",
    "    int_columns_selector = selector(dtype_include=\"int\")\n",
    "    \n",
    "\n",
    "    numerical = data[numeric_columns]\n",
    "    categorical = data[categoical_columns]\n",
    "\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numerical_preprocessor = StandardScaler()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categoical_columns),\n",
    "        ('standard_scaler', numerical_preprocessor, numeric_columns)])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_column = [\n",
    "    \"home_last_wins\",\n",
    "    \"home_last_draws\",\n",
    "    \"home_last_loses\",\n",
    "    \"away_last_wins\",\n",
    "    \"away_last_draws\",\n",
    "    \"away_last_loses\",\n",
    "]\n",
    "categoric_column = [\n",
    "    \"home_code\",\n",
    "    \"away_code\",\n",
    "]\n",
    "\n",
    "df = load_database()\n",
    "features, target = split_database(df)\n",
    "preprocessor = get_encoder(features, categoric_column, numeric_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['home_code', 'away_code']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['home_last_wins',\n",
       "                                                   'home_last_draws',\n",
       "                                                   'home_last_loses',\n",
       "                                                   'away_last_wins',\n",
       "                                                   'away_last_draws',\n",
       "                                                   'away_last_loses'])])),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(n_estimators=150, random_state=42))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "\n",
    "print(\"Random Forest Regression\")\n",
    "regressor = RandomForestRegressor(n_estimators = 150, random_state = 42)\n",
    "model = make_pipeline(preprocessor, regressor)\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.59 degrees.\n",
      "R2: 0.821\n"
     ]
    }
   ],
   "source": [
    "processed_features = preprocessor.fit_transform(features)\n",
    "\n",
    "predictions = model.predict(features)\n",
    "errors_squared = (predictions - target) ** 2\n",
    "\n",
    "print('Mean Squared Error:', round(np.mean(errors_squared), 2), 'degrees.')\n",
    "\n",
    "score = regressor.score(processed_features, target)\n",
    "print('R2:', round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ml/random_forest.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(model, f'{ML_PATH}/random_forest.pkl', compress = 3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_code: 11.74\n",
      "away_code: 10.27\n",
      "home_last_wins: 1.697\n",
      "home_last_draws: 4.127\n",
      "home_last_loses: 8.441\n",
      "away_last_wins: 1.326\n",
      "away_last_draws: 7.439\n",
      "away_last_loses: 4.528\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importances = regressor.feature_importances_\n",
    "for value, var in zip(importances, list(features)):\n",
    "    print(f\"{var}: {value * 1000 :.4}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4de4ed7fc3a7df4272c1d6ebfdc347598fdbf2fda38e88d5b4dbf2ecc8f618"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
