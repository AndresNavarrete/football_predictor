{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def get_fitting_summary(regressor, data, target):\n",
    "    predictions = regressor.predict(data)\n",
    "    errors_squared = (predictions - target) ** 2\n",
    "    \n",
    "    print('Mean Squared Error:', round(np.mean(errors_squared), 2), 'degrees.')\n",
    "\n",
    "    score = regressor.score(data, target)\n",
    "    print('R2:', round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ml/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff_h_a\"] = df.goals_home-df.goals_away\n",
    "df[\"home_code\"] = df.home.astype(\"category\").cat.codes\n",
    "df[\"away_code\"] = df.away.astype(\"category\").cat.codes\n",
    "teams_dict = dict( zip( df.home.astype(\"category\").cat.codes , df.home ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"diff_h_a\"\n",
    "not_usefull_columns = [\n",
    "    target_name,\n",
    "    'home',\n",
    "    'away',\n",
    "    'goals_home',\n",
    "    'goals_away'    \n",
    "    ]\n",
    "\n",
    "data = df.drop(columns=not_usefull_columns)\n",
    "target = df[target_name]\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "float_columns_selector = selector(dtype_include=\"float\")\n",
    "int_columns_selector = selector(dtype_include=\"int\")\n",
    "\n",
    "numerical_columns = float_columns_selector(data) \n",
    "categorical_columns = int_columns_selector(data) \n",
    "\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression\n",
      "Mean Squared Error: 2.84 degrees.\n",
      "R2: 0.203\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVR to the dataset\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "print(\"Support Vector Regression\")\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "model = make_pipeline(preprocessor, regressor)\n",
    "model.fit(data_train, target_train)\n",
    "get_fitting_summary(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron Regression\n",
      "Mean Squared Error: 1.68 degrees.\n",
      "R2: 0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresnavarrete/.local/share/virtualenvs/personal_projects-fsNPPoSg/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting Multi-layer Perceptron regressor to the dataset\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "print(\"Multi-layer Perceptron Regression\")\n",
    "\n",
    "regressor = MLPRegressor(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=500)\n",
    "model = make_pipeline(preprocessor, regressor)\n",
    "model.fit(data_train, target_train)\n",
    "get_fitting_summary(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression\n",
      "Mean Squared Error: 2.14 degrees.\n",
      "R2: 0.399\n"
     ]
    }
   ],
   "source": [
    "# Fitting DecisionTreeRegressor to the dataset\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(\"Decision Tree Regression\")\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "model = make_pipeline(preprocessor, regressor)\n",
    "model.fit(data_train, target_train)\n",
    "get_fitting_summary(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression\n",
      "Mean Squared Error: 1.14 degrees.\n",
      "R2: 0.679\n"
     ]
    }
   ],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"Random Forest Regression\")\n",
    "regressor = RandomForestRegressor(n_estimators = 10000, random_state = 42)\n",
    "model = make_pipeline(preprocessor, regressor)\n",
    "model.fit(data_train, target_train)\n",
    "get_fitting_summary(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"forecast\"] = model.predict(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ml/my_model.pkl']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "joblib.dump(model, 'data/ml/my_model.pkl', compress = 3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_summary = df[[\n",
    "    \"home\",\n",
    "    \"away\",\n",
    "    \"diff_h_a\",\n",
    "    \"forecast\",\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_end_season = { team: 0 for team in teams_dict.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in prediction_summary.iterrows():\n",
    "    if row.forecast > 1:\n",
    "        points_end_season[row.home] += 3\n",
    "        points_end_season[row.away] += 0\n",
    "    elif  row.forecast < -1:\n",
    "        points_end_season[row.home] += 0\n",
    "        points_end_season[row.away] += 3\n",
    "    else:\n",
    "        points_end_season[row.home] += 1\n",
    "        points_end_season[row.away] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Manchester City (80) \n",
      "2. Liverpool (72) \n",
      "3. Manchester United (67) \n",
      "4. Arsenal (63) \n",
      "5. Chelsea (61) \n",
      "6. Tottenham Hotspur (59) \n",
      "7. West Ham United (53) \n",
      "8. Leeds United (51) \n",
      "9. Leicester City (48) \n",
      "10. Aston Villa (46) \n",
      "11. Everton (41) \n",
      "12. Burnley (39) \n",
      "13. Brighton & Hove Albion (38) \n",
      "14. Wolverhampton Wanderers (33) \n",
      "15. Southampton (32) \n",
      "16. Newcastle United (32) \n",
      "17. Crystal Palace (31) \n",
      "18. West Bromwich Albion (25) \n",
      "19. Fulham (25) \n",
      "20. Sheffield United (22) \n"
     ]
    }
   ],
   "source": [
    "results = sorted( ((v,k) for k,v in points_end_season.items()), reverse=True)\n",
    "for index, (points, team) in enumerate(results):\n",
    "    print(f\"{index + 1 }. {team} ({points}) \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('personal_projects-fsNPPoSg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "157c71d8c6bb0527be9cb398e19742748f71aa7f7d4d322a3dcb8476f5991a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
